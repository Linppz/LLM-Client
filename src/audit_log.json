[{"template_name": "code_review.j2", "version_hash": "6bfb2e73b5ab7597eaa355c44724898a75d423082268630a0e504a56ddca54bb", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2a\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684print(1)\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{}\u7684json\u683c\u5f0f\n", "variables": {"lanuage": "python", "your_code": "print(1)", "output_schema": "{}"}, "timestamp": "2026-02-18T20:48:47.264164"}, {"template_name": "code_review.j2", "version_hash": "6bfb2e73b5ab7597eaa355c44724898a75d423082268630a0e504a56ddca54bb", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2a\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684print(1)\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{}\u7684json\u683c\u5f0f\n", "variables": {"lanuage": "python", "your_code": "print(1)", "output_schema": "{}"}, "timestamp": "2026-02-19T12:08:29.250227"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T14:02:03.430128"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T14:06:34.817750"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T14:10:57.068746"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T14:52:22.583304"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T14:58:20.969986"}, {"template_name": "code_review.j2", "version_hash": "a9738c5ff4f6446824b1801b2664c345c1cd065ac2301d67fa41888b1a2557be", "rendered_prompt": "\u4f60\u662f\u4e00\u4e2aProfessor\n\n\n\n\n\u4f60\u662f\u4e00\u4e2a\u5b8c\u7f8e\u7684Python\u521b\u4e16\u4eba\uff0c\u8bf7\u4e3a\u5019\u9009\u4eba\u7684import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n\u4ee3\u7801\uff0c\u505a\u51fa\u5168\u9762\u7684\u5206\u6790\n\u4f60\u7684\u8fd4\u56de\u683c\u5f0f\u5fc5\u987b\u9075\u7167{'$defs': {'CodeIssue': {'properties': {'line': {'minimum': 1, 'title': 'Line', 'type': 'integer'}, 'severity': {'$ref': '#/$defs/Severity'}, 'description': {'minLength': 10, 'title': 'Description', 'type': 'string'}, 'suggested_fix': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'title': 'Suggested Fix'}}, 'required': ['line', 'severity', 'description'], 'title': 'CodeIssue', 'type': 'object'}, 'Severity': {'enum': ['critical', 'major', 'minor'], 'title': 'Severity', 'type': 'string'}}, 'properties': {'overall_score': {'maximum': 10, 'minimum': 1, 'title': 'Overall Score', 'type': 'integer'}, 'issues': {'items': {'$ref': '#/$defs/CodeIssue'}, 'title': 'Issues', 'type': 'array'}, 'summary': {'minLength': 20, 'title': 'Summary', 'type': 'string'}}, 'required': ['overall_score', 'issues', 'summary'], 'title': 'CodeReviewResult', 'type': 'object'}\u7684json\u683c\u5f0f\n", "variables": {"role": "Professor", "lanuage": "Python", "your_code": "import asyncio\nfrom src.llm.factory import LLMFactory\nfrom src.llm.schemas import Message, Role, GenerationConfig\nfrom src.core.config import settings\nfrom src.core.resilience import limiter, concurrency_limiter\nfrom datetime import datetime\n\n\nasync def singletask(client, task_id, prompt):\n    async with limiter:\n        async with concurrency_limiter:\n            start_time = datetime.now()\n            if task_id == 14 or task_id == 17 or task_id == 20:\n                raise Exception('\u6a21\u62df\u5931\u8d25')\n            print(f'{task_id}\u5f00\u59cb\u884c\u52a8')\n            async for word in client.stream(prompt, GenerationConfig()):\n                print(word, end = \"\", flush=True)\n            print(f'\u672c\u6b21\u6d88\u8d39token:{client.tracker.get_usage()}')\n            end_time = datetime.now()\n            print(f'{task_id}\u7ed3\u675f\u884c\u52a8\uff0c\u8017\u65f6{end_time - start_time}\u79d2')\n\nasync def run_batch():\n    client = LLMFactory.get_client()\n    prompt = []\n    prompt.append(Message(role=Role.USER, content = \"\u8c01\u662f\u5b54\u5b50\"))\n    # box = []\n    # for i in range(1, 51):\n        # box.append(singletask(client, i, prompt))\n    # start_time = datetime.now()\n    # result = await asyncio.gather(*box, return_exceptions = True)\n    # end_time = datetime.now()\n    result = await singletask(client, 1,prompt)\n    # success_time = len(box)\n    # for i,s in enumerate(result, 1):\n    #     if isinstance(s, Exception):\n    #         success_time-=1\n    #         print(f\"\u7b2c{i}\u4e2a\u4efb\u52a1\u5931\u8d25\u4e86\")\n    # print(f'\u603b\u8017\u65f6{end_time - start_time} \u79d2, \u5e73\u5747\u8017\u65f6\u4e3a{(end_time - start_time) / 50} \u79d2')\n    # print(f'\u603b\u6210\u529f\u4e86{ success_time} \u4e2a, \u5931\u8d25\u4e86{len(box) - success_time}')\n    await LLMFactory.close_all()\n    # print(f\"\u63a5\u53e3\u5df2\u5173\u95ed\")\n\n\n\nif __name__ == '__main__':\n\n    # asyncio.run(main())\n    asyncio.run(run_batch())\n\n\n\n\n\n", "output_schema": {"$defs": {"CodeIssue": {"properties": {"line": {"minimum": 1, "title": "Line", "type": "integer"}, "severity": {"$ref": "#/$defs/Severity"}, "description": {"minLength": 10, "title": "Description", "type": "string"}, "suggested_fix": {"anyOf": [{"type": "string"}, {"type": "null"}], "default": null, "title": "Suggested Fix"}}, "required": ["line", "severity", "description"], "title": "CodeIssue", "type": "object"}, "Severity": {"enum": ["critical", "major", "minor"], "title": "Severity", "type": "string"}}, "properties": {"overall_score": {"maximum": 10, "minimum": 1, "title": "Overall Score", "type": "integer"}, "issues": {"items": {"$ref": "#/$defs/CodeIssue"}, "title": "Issues", "type": "array"}, "summary": {"minLength": 20, "title": "Summary", "type": "string"}}, "required": ["overall_score", "issues", "summary"], "title": "CodeReviewResult", "type": "object"}}, "timestamp": "2026-02-19T22:46:14.806406"}]